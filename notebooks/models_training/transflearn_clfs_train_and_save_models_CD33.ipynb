{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw-wm8I1n9Mo"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ===============================================================\n",
        "# ===       NOTEBOOK FOR SAVING THE HYPERTUNED MODELS         ===\n",
        "# ===                      FOR CD33                           ===\n",
        "# ===============================================================\n",
        "# ===============================================================\n",
        "\n",
        "__date__= '30-Oct-22'\n",
        "__author__='jeremy charlier'\n",
        "__revised__='30-Oct-22'\n",
        "\n",
        "\"\"\"comments\n",
        "the encoder class is inherited from\n",
        "[1]: \"CRISPR-Net: A Recurrent Convolutional Network QuantiÔ¨Åes\n",
        "CRISPR Off-Target Activities with Mismatches and Indels\", J. Lin et al\n",
        "https://onlinelibrary.wiley.com/doi/epdf/10.1002/advs.201903562\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "path_to_module = 'MODULE_PATH'   # append drive directory to python sys path\n",
        "sys.path.append(path_to_module)\n",
        "sys.path.append(path_to_module+'/code/')   # location of python source code\n",
        "sys.path.append(path_to_module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "from joblib import dump\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier as MLP\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.utils import Bunch\n",
        "from sklearn.metrics import (\n",
        "\tclassification_report, roc_auc_score,\n",
        "\tconfusion_matrix, f1_score,\n",
        "\troc_curve, precision_score, recall_score,\n",
        "\tauc, average_precision_score,\n",
        "\tprecision_recall_curve, accuracy_score)\n",
        "from imblearn.under_sampling import RandomUnderSampler as rus\n",
        "#\n",
        "from transferlearning_datapipeline import datapipeline\n",
        "from simanalysis import getBootStrappedData\n",
        "from transferlearning_modelpipeline import modelpipeline\n",
        "import transferlearning_utils as tlrn\n",
        "import transferlearning_tensorflow_models as tf_models\n",
        "#\n",
        "p = print"
      ],
      "metadata": {
        "id": "BhK5vLFpoPLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rebalanceData(\n",
        "    xtrain, ytrain,\n",
        "    is_sampling = True,\n",
        "    sampling_ratio = 0.8):\n",
        "  # change sampling strat for CIRCLE-SEQ (itrain==1)\n",
        "  # sampling_ratio = 0.2 else 0.8\n",
        "  if is_sampling:\n",
        "    xtrainres, ytrainres = rus(\n",
        "      sampling_strategy = sampling_ratio,\n",
        "      random_state = 0\n",
        "    ).fit_resample(xtrain, ytrain)\n",
        "  else:\n",
        "    xtrainres, ytrainres = xtrain, ytrain\n",
        "  return xtrainres, ytrainres\n",
        "# end function\n",
        "#\n",
        "def getFprTpr(estimator, disp = False):\n",
        "  preds = estimator.yscore\n",
        "  if len(preds.shape) == 2:\n",
        "    ypreds = preds[:,1]\n",
        "  else:\n",
        "    ypreds = preds\n",
        "  fprs, tprs, _ = roc_curve(estimator.y_test, ypreds)\n",
        "  if disp:\n",
        "    print('false positive rates:\\n', fprs)\n",
        "    print('true positive rates:\\n', tprs)\n",
        "  return fprs, tprs\n",
        "#"
      ],
      "metadata": {
        "id": "5l8opHsdotbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def urnd(x): return np.round(x, 3);\n",
        "#\n",
        "def plotRocCurve(\n",
        "\t\testimators,\n",
        "    icol = 1, disp = False):\n",
        "  nwpos = 0\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot([0, 1], [0, 1], 'k--')\n",
        "  # +++ MLP 1 layer +++\n",
        "  fprs, tprs = getFprTpr( estimators[nwpos], disp = disp )\n",
        "  plt.plot(\n",
        "    fprs, tprs,\n",
        "    label = 'MLP 1 layer (AUC: %s \\u00B1 0.001)' % (urnd(auc(fprs, tprs))))\n",
        "  # +++ MLP 2 layers +++\n",
        "  nwpos += 1\n",
        "  fprs, tprs = getFprTpr( estimators[nwpos], disp = disp )\n",
        "  plt.plot(\n",
        "    fprs, tprs,\n",
        "    label = 'MLP 2 layers (AUC: %s \\u00B1 0.001)' % (urnd(auc(fprs, tprs))))\n",
        "  # +++ RF +++\n",
        "  nwpos += 1\n",
        "  fprs, tprs = getFprTpr( estimators[nwpos], disp = disp )\n",
        "  plt.plot(\n",
        "    fprs, tprs,\n",
        "    label = 'RF (AUC: %s \\u00B1 0.001)' % (urnd(auc(fprs, tprs))))\n",
        "  # +++ LR model in position 3 +++\n",
        "  nwpos += 1\n",
        "  fprs, tprs = getFprTpr( estimators[nwpos], disp = disp )\n",
        "  plt.plot(\n",
        "    fprs, tprs,\n",
        "    label='LR (AUC: %s \\u00B1 0.001)' % (urnd(auc(fprs, tprs))))\n",
        "  # dllab = [\n",
        "  #   'FFN3', 'FFN5', 'FFN10',\n",
        "  #   'CNN3', 'CNN5', 'CNN10',\n",
        "  #   'LSTM', 'GRU']\n",
        "  # for nwpos in range(4, 12):\n",
        "  #   clf = estimators[nwpos]\n",
        "  #   plt.plot(\n",
        "  #     clf.fpr, clf.tpr,\n",
        "  #     label = dllab[nwpos-4] + ' (AUC: %s \\u00B1 0.001)' % (clf.roc_auc))\n",
        "  # +++ FNN3 model in position 4 +++\n",
        "  nwpos += 1\n",
        "  clf = estimators[nwpos]\n",
        "  plt.plot(\n",
        "    clf.fpr, clf.tpr,\n",
        "    label='FFN3 (AUC: %s \\u00B1 0.001)' % (clf.roc_auc))\n",
        "  # +++ FNN5 model in position 5 +++\n",
        "  nwpos += 1\n",
        "  clf = estimators[nwpos]\n",
        "  plt.plot(\n",
        "    clf.fpr, clf.tpr,\n",
        "    label='FFN5 (AUC: %s \\u00B1 0.001)' % (clf.roc_auc))\n",
        "  # FNN10 model in position 6\n",
        "  nwpos += 1\n",
        "  clf = estimators[nwpos]\n",
        "  plt.plot(\n",
        "    clf.fpr, clf.tpr,\n",
        "    label='FFN10 (AUC: %s \\u00B1 0.001)' % (clf.roc_auc))\n",
        "  # +++ CNN3 model in position 7 +++\n",
        "  nwpos += 1\n",
        "  clf = estimators[nwpos]\n",
        "  plt.plot(\n",
        "    clf.fpr, clf.tpr,\n",
        "    label = 'CNN3 (AUC: %s \\u00B1 0.001)' % (clf.roc_auc))\n",
        "  # +++ CNN5 model in position 8 +++\n",
        "  nwpos += 1\n",
        "  clf = estimators[nwpos]\n",
        "  plt.plot(\n",
        "    clf.fpr, clf.tpr,\n",
        "    label = 'CNN5 (AUC: %s \\u00B1 0.001)' % (clf.roc_auc))\n",
        "  # +++ CNN10 model in position 9 +++\n",
        "  nwpos += 1\n",
        "  clf = estimators[nwpos]\n",
        "  plt.plot(\n",
        "    clf.fpr, clf.tpr,\n",
        "    label = 'CNN10 (AUC: %s \\u00B1 0.001)' % (clf.roc_auc))\n",
        "  # +++ LSTM model in position 10 +++\n",
        "  nwpos += 1\n",
        "  clf = estimators[nwpos]\n",
        "  plt.plot(\n",
        "    clf.fpr, clf.tpr,\n",
        "    label = 'LSTM (AUC: %s \\u00B1 0.001)' % (clf.roc_auc))\n",
        "  # +++ GRU model in position 11 +++\n",
        "  nwpos += 1\n",
        "  clf = estimators[nwpos]\n",
        "  plt.plot(\n",
        "    clf.fpr, clf.tpr,\n",
        "    label = 'GRU (AUC: %s \\u00B1 0.001)' % (clf.roc_auc))\n",
        "  # +++ plot legend +++\n",
        "  plt.xlabel('False positive rate')\n",
        "  plt.ylabel('True positive rate')\n",
        "  plt.legend(loc='best')\n",
        "  # plt.show()\n",
        "  plt.savefig('plot1.pdf')\n",
        "#"
      ],
      "metadata": {
        "id": "NVVS10cq0uU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === VARIABLE INITIALIZATION ===\n",
        "issavemodels = True # save models (Y=True / N=False)\n",
        "issklearnmodels = True # for sklearn models\n",
        "isfnnmodels = True # for FNNs models\n",
        "iscnnmodels = True # for CNNs models\n",
        "isrnnmodels = True # for RNNs models\n",
        "#\n",
        "# === READ ENCODED DATA ===\n",
        "is_read_pkl_encoded_data = True\n",
        "if is_read_pkl_encoded_data:\n",
        "  f = open(path_to_module+'/data/encoded_data.pkl', 'rb')\n",
        "  encdata = pkl.load(f)\n",
        "  f.close()\n",
        "else:\n",
        "  encdata = datapipeline()"
      ],
      "metadata": {
        "id": "XfQ0x2Syocu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === DATA CD33 ===\n",
        "idata = 0\n",
        "data = encdata[0]\n",
        "xtrain, xtest, ytrain, ytest = tlrn.dataSplitRF(data)\n",
        "xtrainres, ytrainres = xtrain, ytrain\n",
        "#\n",
        "is_verbose_training = False"
      ],
      "metadata": {
        "id": "MsRCZItD1-3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# ========================================================\n",
        "#                      SKLEARN MODELS\n",
        "# ========================================================\n",
        "# ========================================================\n",
        "if issklearnmodels:\n",
        "  # === MLP 1 LAYER ===\n",
        "  print('=== MLP 1 LAYER TRAINING ===')\n",
        "  clf = MLP(\n",
        "    hidden_layer_sizes=(230,),\n",
        "    activation = 'tanh', solver = 'adam',\n",
        "    learning_rate = 'invscaling',\n",
        "    early_stopping = False,\n",
        "    max_iter = 1000, random_state = 0 )\n",
        "  mlp_cd33 = modelpipeline(\n",
        "      clf,\n",
        "      xtrainres, ytrainres,\n",
        "      xtest, ytest, is_verbose_training\n",
        "    ).modelTrain()\n",
        "  mlp_cd33 = mlp_cd33.modelPredict()\n",
        "  #\n",
        "  # === MLP 2 LAYERS ===\n",
        "  print('=== MLP 2 LAYERS TRAINING ===')\n",
        "  clf = MLP(\n",
        "    hidden_layer_sizes=( 216, 25 ),\n",
        "    activation = 'tanh', solver = 'adam',\n",
        "    learning_rate = 'invscaling',\n",
        "    early_stopping = False,\n",
        "    max_iter = 1000, random_state = 0\n",
        "  )\n",
        "  mlp_cd33_2layers = modelpipeline(\n",
        "      clf,\n",
        "      xtrainres, ytrainres,\n",
        "      xtest, ytest, is_verbose_training\n",
        "    ).modelTrain()\n",
        "  mlp_cd33_2layers = mlp_cd33_2layers.modelPredict()\n",
        "  #\n",
        "  # === RANDOM FOREST ===\n",
        "  print('=== RANDOM FOREST TRAINING ===')\n",
        "  clf = RandomForestClassifier(\n",
        "    n_estimators = 485, criterion = 'entropy',\n",
        "    n_jobs = -1, random_state = 0)\n",
        "  rf_cd33 = modelpipeline(\n",
        "      clf,\n",
        "      xtrainres, ytrainres,\n",
        "      xtest, ytest, is_verbose_training\n",
        "    ).modelTrain()\n",
        "  rf_cd33 = rf_cd33.modelPredict()\n",
        "  #\n",
        "  # === LOGISTIC REGRESSION ===\n",
        "  print('=== LOGISTIC REGRESSION TRAINING ===')\n",
        "  clf = LogisticRegression(\n",
        "    solver = 'newton-cg',\n",
        "    C = 0.01274, max_iter = 10000,\n",
        "    n_jobs = -1, random_state = 0)\n",
        "  lr_cd33 = modelpipeline(\n",
        "      clf,\n",
        "      xtrainres, ytrainres,\n",
        "      xtest, ytest, is_verbose_training\n",
        "    ).modelTrain()\n",
        "  lr_cd33 = lr_cd33.modelPredict()\n",
        "  #\n",
        "  if issavemodels:\n",
        "    print('=== SAVING SKLEARN MODELS ===')\n",
        "    dump(mlp_cd33, path_to_module+'/saved_models/mlp_cd33.joblib')\n",
        "    dump(mlp_cd33_2layers, path_to_module+'/saved_models/mlp_2layers_cd33.joblib')\n",
        "    dump(rf_cd33, path_to_module+'/saved_models/rf_cd33.joblib')\n",
        "    dump(lr_cd33, path_to_module+'/saved_models/lr_cd33.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWACnvXIK1sg",
        "outputId": "4c96f50c-964d-4aac-fe21-ba27a76584be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MLP 1 LAYER TRAINING ===\n",
            "=== MLP 2 LAYERS TRAINING ===\n",
            "=== RANDOM FOREST TRAINING ===\n",
            "=== LOGISTIC REGRESSION TRAINING ===\n",
            "=== SAVING SKLEARN MODELS ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# ========================================================\n",
        "#                      FNNS MODELS\n",
        "# ========================================================\n",
        "# ========================================================\n",
        "if isfnnmodels:\n",
        "  max_iter_training = 25\n",
        "  # === DATA FOR FFNS ===\n",
        "  data_test_size = tf_models.define_data_test_size(idata)\n",
        "  x_train_ffns, x_test_ffns, y_train_ffns, y_test_ffns = tf_models.data_split_for_fnns(\n",
        "    encdata[idata],\n",
        "    testsize = data_test_size\n",
        "  )\n",
        "  x_boot_ffns, y_boot_ffns = tf_models.bootstrapForHypertuning( encdata[idata] )\n",
        "  data_dict = {\n",
        "    'x_train': x_train_ffns, 'y_train': y_train_ffns,\n",
        "    'x_boot': x_boot_ffns, 'y_boot': y_boot_ffns,\n",
        "    'x_test': x_test_ffns, 'y_test': y_test_ffns\n",
        "  }\n",
        "  # === FFN 3 LAYERS ===\n",
        "  best_ffn3_roc = 0\n",
        "  for iter in range(max_iter_training):\n",
        "    params_grid_ffn3 = {\n",
        "      'unit_layer_1': 128,\n",
        "      'unit_layer_2': 128,\n",
        "      'unit_layer_3': 200,\n",
        "      'unit_dropout_1': 0.05,\n",
        "      'is_batch_normalization_1': True,\n",
        "      'unit_batch': 256\n",
        "    }\n",
        "    ffn3_cd33_tmp = tf_models.dlModelsPipeline(\n",
        "      tf_models.model_ffn3,\n",
        "      data_dict,\n",
        "      params_grid_ffn3\n",
        "    )\n",
        "    ffn3_cd33_tmp.modelTrain()\n",
        "    ffn3_cd33_tmp.modelPredict()\n",
        "    if ffn3_cd33_tmp.roc_auc > best_ffn3_roc:\n",
        "      best_ffn3_roc = ffn3_cd33_tmp.roc_auc\n",
        "      ffn3_cd33 = ffn3_cd33_tmp\n",
        "  print('> best roc auc FFN3:', ffn3_cd33.roc_auc)\n",
        "  #\n",
        "  # === FFN 5 LAYERS ===\n",
        "  best_ffn5_roc = 0\n",
        "  for iter in range(max_iter_training):\n",
        "    params_grid_ffn5 = {\n",
        "      'unit_layer_1': 32,\n",
        "      'unit_layer_2': 256,\n",
        "      'unit_layer_3': 64,\n",
        "      'unit_layer_4': 100,\n",
        "      'unit_layer_5': 256,\n",
        "      'unit_dropout_1': 0.15,\n",
        "      'unit_dropout_2': 0.1,\n",
        "      'is_batch_normalization_1': True,\n",
        "      'is_batch_normalization_2': True,\n",
        "      'unit_batch': 256\n",
        "    }\n",
        "    ffn5_cd33_tmp = tf_models.dlModelsPipeline(\n",
        "      tf_models.model_ffn5,\n",
        "      data_dict,\n",
        "      params_grid_ffn5\n",
        "    )\n",
        "    ffn5_cd33_tmp.modelTrain()\n",
        "    ffn5_cd33_tmp.modelPredict()\n",
        "    if ffn5_cd33_tmp.roc_auc > best_ffn5_roc:\n",
        "      best_ffn5_roc = ffn5_cd33_tmp.roc_auc\n",
        "      ffn5_cd33 = ffn5_cd33_tmp\n",
        "  print('> best roc auc FFN5:', ffn5_cd33.roc_auc)\n",
        "  #\n",
        "  # === FFN 10 LAYERS ===\n",
        "  best_ffn10_roc = 0\n",
        "  for iter in range(max_iter_training):\n",
        "    params_grid_ffn10 = {\n",
        "      'unit_layer_1': 200,\n",
        "      'unit_layer_2': 75,\n",
        "      'unit_layer_3': 64,\n",
        "      'unit_layer_4': 64,\n",
        "      'unit_layer_5': 200,\n",
        "      'unit_layer_6': 128,\n",
        "      'unit_layer_7': 256,\n",
        "      'unit_layer_8': 64,\n",
        "      'unit_layer_9': 8,\n",
        "      'unit_layer_10': 8,\n",
        "      'unit_dropout_1': 0,\n",
        "      'unit_dropout_2': 0.15,\n",
        "      'unit_dropout_3': 0.3,\n",
        "      'unit_dropout_4': 0.05,\n",
        "      'is_batch_normalization_1': True,\n",
        "      'is_batch_normalization_2': True,\n",
        "      'is_batch_normalization_3': True,\n",
        "      'is_batch_normalization_4': True,\n",
        "      'is_batch_normalization_5': True,\n",
        "      'is_batch_normalization_6': True,\n",
        "      'unit_batch': 32\n",
        "    }\n",
        "    ffn10_cd33_tmp = tf_models.dlModelsPipeline(\n",
        "      tf_models.model_ffn10,\n",
        "      data_dict,\n",
        "      params_grid_ffn10\n",
        "    )\n",
        "    ffn10_cd33_tmp.modelTrain()\n",
        "    ffn10_cd33_tmp.modelPredict()\n",
        "    if ffn10_cd33_tmp.roc_auc > best_ffn10_roc:\n",
        "      best_ffn10_roc = ffn10_cd33_tmp.roc_auc\n",
        "      ffn10_cd33 = ffn10_cd33_tmp\n",
        "  print('> best roc auc FFN10:', ffn10_cd33.roc_auc)\n",
        "  #\n",
        "  # === SAVING FFNS ===\n",
        "  if issavemodels:\n",
        "    print('=== SAVING FNNS MODELS ===')\n",
        "    ffn3_cd33.trained_model.save(path_to_module+'/saved_models/ffn3_cd33')\n",
        "    ffn5_cd33.trained_model.save(path_to_module+'/saved_models/ffn5_cd33')\n",
        "    ffn10_cd33.trained_model.save(path_to_module+'/saved_models/ffn10_cd33')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTar5QxnzFPo",
        "outputId": "3dac40b6-19c8-40a4-965c-2ff6482ce3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> best roc auc FFN3: 0.964\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> best roc auc FFN5: 0.95\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> FFN10 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> best roc auc FFN10: 0.956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# ========================================================\n",
        "#                      CNNS MODELS\n",
        "# ========================================================\n",
        "# ========================================================\n",
        "if iscnnmodels:\n",
        "  max_iter_training = 25\n",
        "  # === DATA FOR CNNS ===\n",
        "  data_test_size = tf_models.define_data_test_size(idata)\n",
        "  x_train_cnns, x_test_cnns, y_train_cnns, y_test_cnns = tf_models.data_split_for_cnns(\n",
        "    encdata[idata],\n",
        "    testsize = data_test_size\n",
        "  )\n",
        "  x_train_cnns = x_train_cnns.reshape(-1, 24, 7, 1)\n",
        "  x_test_cnns = x_test_cnns.reshape(-1, 24, 7, 1)\n",
        "  x_boot_cnns, y_boot_cnns = tf_models.bootstrapForHypertuning( encdata[idata] )\n",
        "  x_boot_cnns = x_boot_cnns.reshape(-1, 24, 7, 1)\n",
        "  data_dict = {\n",
        "    'x_train': x_train_cnns, 'y_train': y_train_cnns,\n",
        "    'x_boot': x_boot_cnns, 'y_boot': y_boot_cnns,\n",
        "    'x_test': x_test_cnns, 'y_test': y_test_cnns\n",
        "  }\n",
        "  # === CNN 3 LAYERS ===\n",
        "  best_cnn3_roc = 0\n",
        "  for iter in range(max_iter_training):\n",
        "    params_grid_cnn3 = {\n",
        "    'unit_layer_1' : 128,\n",
        "    'unit_layer_2' : 256,\n",
        "    'activation_layer_1' : 'tanh',\n",
        "    'activation_layer_2' : 'tanh',\n",
        "    'activation_layer_3' : 'tanh',\n",
        "    'unit_dropout_1' : 0.1,\n",
        "    'unit_dropout_2' : 0,\n",
        "    'is_batch_normalization_1' : True,\n",
        "    'is_batch_normalization_2' : True,\n",
        "    'unit_batch' : 128}\n",
        "    cnn3_cd33_tmp = tf_models.dlModelsPipeline(\n",
        "      tf_models.model_cnn3,\n",
        "      data_dict,\n",
        "      params_grid_cnn3\n",
        "    )\n",
        "    cnn3_cd33_tmp.modelTrain()\n",
        "    cnn3_cd33_tmp.modelPredict()\n",
        "    if cnn3_cd33_tmp.roc_auc > best_cnn3_roc:\n",
        "      best_cnn3_roc = cnn3_cd33_tmp.roc_auc\n",
        "      cnn3_cd33 = cnn3_cd33_tmp\n",
        "  print('> best roc auc CNN3:', cnn3_cd33.roc_auc)\n",
        "  #\n",
        "  # === CNN 5 LAYERS ===\n",
        "  best_cnn5_roc = 0\n",
        "  for iter in range(max_iter_training):\n",
        "    params_grid_cnn5 = {\n",
        "      'unit_layer_1' : 200,\n",
        "      'unit_layer_2' : 128,\n",
        "      'unit_layer_3' : 32,\n",
        "      'unit_layer_4' : 64,\n",
        "      'activation_layer_1' : 'relu',\n",
        "      'activation_layer_2' : 'tanh',\n",
        "      'activation_layer_3' : 'relu',\n",
        "      'activation_layer_4' : 'softmax',\n",
        "      'activation_layer_5' : 'tanh',\n",
        "      'unit_dropout_1' : 0,\n",
        "      'unit_dropout_2' : 0,\n",
        "      'is_batch_normalization_1' : True,\n",
        "      'is_batch_normalization_2' : True,\n",
        "      'is_batch_normalization_3' : True,\n",
        "      'unit_batch' : 256}\n",
        "    cnn5_cd33_tmp = tf_models.dlModelsPipeline(\n",
        "      tf_models.model_cnn5,\n",
        "      data_dict,\n",
        "      params_grid_cnn5\n",
        "    )\n",
        "    cnn5_cd33_tmp.modelTrain()\n",
        "    cnn5_cd33_tmp.modelPredict()\n",
        "    if cnn5_cd33_tmp.roc_auc > best_cnn5_roc:\n",
        "      best_cnn5_roc = cnn5_cd33_tmp.roc_auc\n",
        "      cnn5_cd33 = cnn5_cd33_tmp\n",
        "  print('> best roc auc CNN5:', cnn5_cd33.roc_auc)\n",
        "  #\n",
        "  # === CNN 10 LAYERS ===\n",
        "  best_cnn10_roc = 0\n",
        "  for iter in range(max_iter_training):\n",
        "    params_grid_cnn10 = {\n",
        "      'unit_layer_1' : 100,\n",
        "      'unit_layer_2' : 256,\n",
        "      'unit_layer_3' : 256,\n",
        "      'unit_layer_4' : 128,\n",
        "      'unit_layer_5' : 32,\n",
        "      'unit_layer_6' : 16,\n",
        "      'unit_layer_7' : 32,\n",
        "      'unit_layer_8' : 8,\n",
        "      'unit_layer_9' : 32,\n",
        "      'activation_layer_1' : 'relu',\n",
        "      'activation_layer_2' : 'tanh',\n",
        "      'activation_layer_3' : 'softmax',\n",
        "      'activation_layer_4' : 'softmax',\n",
        "      'activation_layer_5' : 'softmax',\n",
        "      'activation_layer_6' : 'tanh',\n",
        "      'activation_layer_7' : 'softmax',\n",
        "      'activation_layer_8' : 'tanh',\n",
        "      'activation_layer_9' : 'softmax',\n",
        "      'activation_layer_10' : 'relu',\n",
        "      'unit_dropout_1' : 0.15,\n",
        "      'unit_dropout_2' : 0.15,\n",
        "      'unit_dropout_3' : 0.15,\n",
        "      'unit_dropout_4' : 0.05,\n",
        "      'unit_dropout_5' : 0.1,\n",
        "      'unit_dropout_6' : 0.05,\n",
        "      'is_batch_normalization_1' : True,\n",
        "      'is_batch_normalization_2' : True,\n",
        "      'is_batch_normalization_3' : True,\n",
        "      'is_batch_normalization_4' : True,\n",
        "      'is_batch_normalization_5' : True,\n",
        "      'is_batch_normalization_6' : True,\n",
        "      'is_batch_normalization_7' : True,\n",
        "      'unit_batch' : 64}\n",
        "    cnn10_cd33_tmp = tf_models.dlModelsPipeline(\n",
        "      tf_models.model_cnn10,\n",
        "      data_dict,\n",
        "      params_grid_cnn10\n",
        "    )\n",
        "    cnn10_cd33_tmp.modelTrain()\n",
        "    cnn10_cd33_tmp.modelPredict()\n",
        "    if cnn10_cd33_tmp.roc_auc > best_cnn10_roc:\n",
        "      best_cnn10_roc = cnn10_cd33_tmp.roc_auc\n",
        "      cnn10_cd33 = cnn10_cd33_tmp\n",
        "  print('> best roc auc CNN10:', cnn10_cd33.roc_auc)\n",
        "  #\n",
        "  # === SAVING CNNS ===\n",
        "  if issavemodels:\n",
        "    print('=== SAVING CNNS MODELS ===')\n",
        "    cnn3_cd33.trained_model.save(path_to_module+'/saved_models/cnn3_cd33')\n",
        "    cnn5_cd33.trained_model.save(path_to_module+'/saved_models/cnn5_cd33')\n",
        "    cnn10_cd33.trained_model.save(path_to_module+'/saved_models/cnn10_cd33')"
      ],
      "metadata": {
        "id": "ySrkbpnuo0H_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162a1570-1eb0-44c3-ed0b-506deca8bcc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN3 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> best roc auc CNN3: 0.919\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> CNN5 training\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "> best roc auc CNN5: 0.97\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 1s 5ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 1s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> CNN10 training\n",
            "46/46 [==============================] - 0s 3ms/step\n",
            "> best roc auc CNN10: 0.954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# ========================================================\n",
        "#                      RNNS MODELS\n",
        "# ========================================================\n",
        "# ========================================================\n",
        "if isrnnmodels:\n",
        "  max_iter_training = 25\n",
        "  # === DATA FOR RNNS ===\n",
        "  data_test_size = tf_models.define_data_test_size(idata)\n",
        "  x_train_rnns, x_test_rnns, y_train_rnns, y_test_rnns = tf_models.data_split_for_cnns(\n",
        "    encdata[idata], testsize = data_test_size\n",
        "  )\n",
        "  x_boot_rnns, y_boot_rnns = tf_models.bootstrapForHypertuning(\n",
        "    encdata[idata], is_reshape = False\n",
        "  )\n",
        "  data_dict = {\n",
        "    'x_train': x_train_rnns, 'y_train': y_train_rnns,\n",
        "    'x_boot': x_boot_rnns, 'y_boot': y_boot_rnns,\n",
        "    'x_test': x_test_rnns, 'y_test': y_test_rnns\n",
        "  }\n",
        "  # === LSTM 3 LAYERS ===\n",
        "  best_lstm3_roc = 0\n",
        "  for iter in range(max_iter_training):\n",
        "    params_grid_lstm3 = {\n",
        "      'unit_layer_1': 128,\n",
        "      'unit_layer_2': 75,\n",
        "      'activation_layer_1': 'relu',\n",
        "      'activation_layer_2': 'softmax',\n",
        "      'activation_layer_3': 'tanh',\n",
        "      'unit_dropout_1': 0.15,\n",
        "      'unit_dropout_2': 0.15,\n",
        "      'is_batch_normalization_1': True,\n",
        "      'is_batch_normalization_2': True,\n",
        "      'unit_batch': 256\n",
        "    }\n",
        "    lstm3_cd33_tmp = tf_models.dlModelsPipeline(\n",
        "      tf_models.model_lstm3,\n",
        "      data_dict,\n",
        "      params_grid_lstm3\n",
        "    )\n",
        "    lstm3_cd33_tmp.modelTrain()\n",
        "    lstm3_cd33_tmp.modelPredict()\n",
        "    if lstm3_cd33_tmp.roc_auc > best_lstm3_roc:\n",
        "      best_lstm3_roc = lstm3_cd33_tmp.roc_auc\n",
        "      lstm3_cd33 = lstm3_cd33_tmp\n",
        "  print('> best roc auc LSTM3:', lstm3_cd33.roc_auc)\n",
        "  # === GRU 3 LAYERS ===\n",
        "  best_gru3_roc = 0\n",
        "  for iter in range(max_iter_training):\n",
        "    params_grid_gru3 = {\n",
        "      'unit_layer_1': 256,\n",
        "      'unit_layer_2': 64,\n",
        "      'activation_layer_1': 'relu',\n",
        "      'activation_layer_2': 'softmax',\n",
        "      'activation_layer_3': 'tanh',\n",
        "      'unit_dropout_1': 0.1,\n",
        "      'unit_dropout_2': 0.1,\n",
        "      'is_batch_normalization_1': True,\n",
        "      'is_batch_normalization_2': True,\n",
        "      'unit_batch': 32\n",
        "    }\n",
        "    gru3_cd33_tmp = tf_models.dlModelsPipeline(\n",
        "      tf_models.model_gru3,\n",
        "      data_dict,\n",
        "      params_grid_gru3\n",
        "    )\n",
        "    gru3_cd33_tmp.modelTrain()\n",
        "    gru3_cd33_tmp.modelPredict()\n",
        "    if gru3_cd33_tmp.roc_auc > best_gru3_roc:\n",
        "      best_gru3_roc = gru3_cd33_tmp.roc_auc\n",
        "      gru3_cd33 = gru3_cd33_tmp\n",
        "  print('> best roc auc GRU3:', gru3_cd33.roc_auc)\n",
        "  #\n",
        "  # === SAVING RNNS ===\n",
        "  if issavemodels:\n",
        "    print('=== SAVING RNNS MODELS ===')\n",
        "    lstm3_cd33.trained_model.save(path_to_module+'/saved_models/lstm3_cd33')\n",
        "    gru3_cd33.trained_model.save(path_to_module+'/saved_models/gru3_cd33')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxBiumvLWCzD",
        "outputId": "09b39b61-4784-4ca0-f884-76dbddf87419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> LSTM3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> best roc auc LSTM3: 0.921\n",
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> GRU3 training\n",
            "46/46 [==============================] - 0s 6ms/step\n",
            "> best roc auc GRU3: 0.937\n"
          ]
        }
      ]
    }
  ]
}