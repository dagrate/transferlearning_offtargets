{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw-wm8I1n9Mo"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ===============================================================\n",
        "# ===          NOTEBOOK FOR HYPERPARAMETERS SEARCH            ===\n",
        "# ===                   FOR THE DL MODELS                     ===\n",
        "# ===          WITH CD33, CIRCLE-SEQ AND SITE-SEQ             ===\n",
        "# ===============================================================\n",
        "# ===============================================================\n",
        "__date__='20-Apr-22'\n",
        "__author__='jeremy charlier'\n",
        "__revised__ = '14-May-22'\n",
        "\n",
        "\"\"\"comments:\n",
        "the encoder class is inherited from\n",
        "[1]: \"CRISPR-Net: A Recurrent Convolutional Network Quantiï¬es\n",
        "CRISPR Off-Target Activities with Mismatches and Indels\", J. Lin et al\n",
        "https://onlinelibrary.wiley.com/doi/epdf/10.1002/advs.201903562\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "path_to_module = 'MODULE_PATH' # append drive directory to python sys path\n",
        "sys.path.append(path_to_module)\n",
        "sys.path.append(path_to_module+'/code/')   # location of python source code\n",
        "sys.path.append(path_to_module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "#\n",
        "from transferlearning_datapipeline import datapipeline\n",
        "import transferlearning_tensorflow_models as tf_models"
      ],
      "metadata": {
        "id": "BhK5vLFpoPLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === READ ENCODED DATA ===\n",
        "is_read_pkl_encoded_data = True\n",
        "if is_read_pkl_encoded_data:\n",
        "  f = open(path_to_module+'/data/encoded_data.pkl', 'rb')\n",
        "  encdata = pkl.load(f)\n",
        "  f.close()\n",
        "else:\n",
        "  encdata = datapipeline()"
      ],
      "metadata": {
        "id": "XfQ0x2Syocu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === HYPERTUNING FOR MODEL LSTM 3 LAYERS ===\n",
        "# warning: tensorflow implementation only support tanh activation for\n",
        "# GPU calculation. Use CPU runtime for hypertuning with RNNs.\n",
        "params_grid = {\n",
        "  'layer_1_grid': [32, 64, 128, 200, 256],\n",
        "  'layer_2_grid': [32, 64, 75, 100, 128, 200, 256],\n",
        "  'activation_layer_1_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_2_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_3_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'dropout_1_grid': [0, .05, .1, .15],\n",
        "  'dropout_2_grid': [0, .05, .1, .15],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(\n",
        "  encdata,\n",
        "  tf_models.model_lstm3,\n",
        "  params_grid,\n",
        "  n_iterations = 50,\n",
        "  is_verbose_iterations = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwsgDQsCEwM2",
        "outputId": "6617150e-4126-4d7f-c766-a2218333ead8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 0\n",
            "x_boot.shape: (4000, 24, 7)\n",
            "x_test.shape: (1456, 24, 7, 1)\n",
            ">> LSTM3 hypertuning.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\n",
            "\n",
            "best score: 0.947\n",
            "best_params = {'unit_layer_1': 128, 'unit_layer_2': 75, 'activation_layer_1': 'relu', 'activation_layer_2': 'softmax', 'activation_layer_3': 'tanh', 'unit_dropout_1': 0.15, 'unit_dropout_2': 0.15, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 256}\n",
            "\n",
            "current data set: 1\n",
            "x_boot.shape: (4000, 24, 7)\n",
            "x_test.shape: (5850, 24, 7, 1)\n",
            ">> LSTM3 hypertuning.\n",
            "WARNING:tensorflow:Layer lstm_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\n",
            "\n",
            "best score: 0.845\n",
            "best_params = {'unit_layer_1': 32, 'unit_layer_2': 200, 'activation_layer_1': 'softmax', 'activation_layer_2': 'softmax', 'activation_layer_3': 'tanh', 'unit_dropout_1': 0.15, 'unit_dropout_2': 0.15, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 32}\n",
            "\n",
            "current data set: 2\n",
            "x_boot.shape: (4000, 24, 7)\n",
            "x_test.shape: (5444, 24, 7, 1)\n",
            ">> LSTM3 hypertuning.\n",
            "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_105 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_110 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_111 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_114 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_119 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_123 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_124 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_125 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\n",
            "\n",
            "best score: 0.865\n",
            "best_params = {'unit_layer_1': 200, 'unit_layer_2': 100, 'activation_layer_1': 'tanh', 'activation_layer_2': 'relu', 'activation_layer_3': 'relu', 'unit_dropout_1': 0.05, 'unit_dropout_2': 0.05, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 32}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HYPERTUNING FOR MODEL GRU 3 LAYERS ===\n",
        "# warning: tensorflow implementation only support tanh activation for\n",
        "# GPU calculation. Use CPU runtime for hypertuning with RNNs.\n",
        "params_grid = {\n",
        "  'layer_1_grid': [32, 64, 128, 200, 256],\n",
        "  'layer_2_grid': [32, 64, 75, 100, 128, 200, 256],\n",
        "  'activation_layer_1_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_2_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_3_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'dropout_1_grid': [0, .05, .1, .15],\n",
        "  'dropout_2_grid': [0, .05, .1, .15],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(\n",
        "  encdata,\n",
        "  tf_models.model_gru3,\n",
        "  params_grid,\n",
        "  n_iterations = 50,\n",
        "  is_verbose_iterations = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH6yrZovyQiE",
        "outputId": "74934d6a-9bd2-406b-8f59-03d5943a8a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 0\n",
            "x_boot.shape: (4000, 24, 7)\n",
            "x_test.shape: (1456, 24, 7, 1)\n",
            ">> GRU3 hypertuning.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\n",
            "\n",
            "best score: 0.931\n",
            "best_params = {'unit_layer_1': 256, 'unit_layer_2': 64, 'activation_layer_1': 'relu', 'activation_layer_2': 'softmax', 'activation_layer_3': 'tanh', 'unit_dropout_1': 0.1, 'unit_dropout_2': 0.1, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 32}\n",
            "\n",
            "current data set: 1\n",
            "x_boot.shape: (4000, 24, 7)\n",
            "x_test.shape: (5850, 24, 7, 1)\n",
            ">> GRU3 hypertuning.\n",
            "WARNING:tensorflow:Layer gru_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\n",
            "\n",
            "best score: 0.865\n",
            "best_params = {'unit_layer_1': 200, 'unit_layer_2': 256, 'activation_layer_1': 'relu', 'activation_layer_2': 'relu', 'activation_layer_3': 'relu', 'unit_dropout_1': 0, 'unit_dropout_2': 0, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 32}\n",
            "\n",
            "current data set: 2\n",
            "x_boot.shape: (4000, 24, 7)\n",
            "x_test.shape: (5444, 24, 7, 1)\n",
            ">> GRU3 hypertuning.\n",
            "WARNING:tensorflow:Layer gru_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_103 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_104 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_106 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_107 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_108 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_109 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_112 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_113 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_115 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_117 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_118 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_120 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_121 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_122 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_126 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_127 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_129 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_130 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_131 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "\n",
            "\n",
            "best score: 0.842\n",
            "best_params = {'unit_layer_1': 256, 'unit_layer_2': 128, 'activation_layer_1': 'tanh', 'activation_layer_2': 'relu', 'activation_layer_3': 'tanh', 'unit_dropout_1': 0.05, 'unit_dropout_2': 0.15, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 32}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HYPERTUNING FOR MODEL CNN 3 LAYERS ===\n",
        "params_grid = {\n",
        "  'layer_1_grid': [100, 128, 200, 256],\n",
        "  'layer_2_grid': [32, 64, 75, 100, 128, 200, 256],\n",
        "  'activation_layer_1_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_2_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_3_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'dropout_1_grid': [0, .05, .1, .15],\n",
        "  'dropout_2_grid': [0, .05, .1, .15],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(\n",
        "  encdata,\n",
        "  tf_models.model_cnn3,\n",
        "  params_grid,\n",
        "  n_iterations = 50,\n",
        "  is_verbose_iterations = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHc_F4kEpOvC",
        "outputId": "09d0c08d-e7f1-4c8d-ad6d-6bbfc9c5b5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 0\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (1456, 24, 7, 1)\n",
            ">> CNN3 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.948\n",
            "best_params = {'unit_layer_1': 128, 'unit_layer_2': 256, 'activation_layer_1': 'tanh', 'activation_layer_2': 'tanh', 'activation_layer_3': 'tanh', 'unit_dropout_1': 0.1, 'unit_dropout_2': 0, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 128}\n",
            "\n",
            "current data set: 1\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (5850, 24, 7, 1)\n",
            ">> CNN3 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.816\n",
            "best_params = {'unit_layer_1': 256, 'unit_layer_2': 32, 'activation_layer_1': 'relu', 'activation_layer_2': 'tanh', 'activation_layer_3': 'tanh', 'unit_dropout_1': 0, 'unit_dropout_2': 0, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 128}\n",
            "\n",
            "current data set: 2\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (5444, 24, 7, 1)\n",
            ">> CNN3 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.769\n",
            "best_params = {'unit_layer_1': 256, 'unit_layer_2': 128, 'activation_layer_1': 'softmax', 'activation_layer_2': 'tanh', 'activation_layer_3': 'tanh', 'unit_dropout_1': 0.1, 'unit_dropout_2': 0.05, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 128}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HYPERTUNING FOR MODEL CNN 5 LAYERS ===\n",
        "params_grid = {\n",
        "  'layer_1_grid': [100, 128, 200, 256],\n",
        "  'layer_2_grid': [100, 128, 200, 256],\n",
        "  'layer_3_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_4_grid': [8, 16, 32, 64, 75],\n",
        "  'activation_layer_1_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_2_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_3_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_4_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_5_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'dropout_1_grid': [0, .05, .1, .15],\n",
        "  'dropout_2_grid': [0, .05, .1, .15],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(\n",
        "  encdata,\n",
        "  tf_models.model_cnn5,\n",
        "  params_grid,\n",
        "  n_iterations = 150,\n",
        "  is_verbose_iterations = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq8EcjnZr8Ld",
        "outputId": "e1a2e239-f938-4871-ca07-31917ca0ebf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 0\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (1456, 24, 7, 1)\n",
            ">> CNN5 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.972\n",
            "best_params = {'unit_layer_1': 200, 'unit_layer_2': 128, 'unit_layer_3': 32, 'unit_layer_4': 64, 'activation_layer_1': 'relu', 'activation_layer_2': 'tanh', 'activation_layer_3': 'relu', 'activation_layer_4': 'softmax', 'activation_layer_5': 'tanh', 'unit_dropout_1': 0, 'unit_dropout_2': 0, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'is_batch_normalization_3': True, 'unit_batch': 256}\n",
            "\n",
            "current data set: 1\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (5850, 24, 7, 1)\n",
            ">> CNN5 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.776\n",
            "best_params = {'unit_layer_1': 200, 'unit_layer_2': 200, 'unit_layer_3': 64, 'unit_layer_4': 75, 'activation_layer_1': 'tanh', 'activation_layer_2': 'softmax', 'activation_layer_3': 'softmax', 'activation_layer_4': 'softmax', 'activation_layer_5': 'tanh', 'unit_dropout_1': 0, 'unit_dropout_2': 0.1, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'is_batch_normalization_3': True, 'unit_batch': 128}\n",
            "\n",
            "current data set: 2\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (5444, 24, 7, 1)\n",
            ">> CNN5 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.797\n",
            "best_params = {'unit_layer_1': 128, 'unit_layer_2': 256, 'unit_layer_3': 75, 'unit_layer_4': 64, 'activation_layer_1': 'tanh', 'activation_layer_2': 'softmax', 'activation_layer_3': 'softmax', 'activation_layer_4': 'tanh', 'activation_layer_5': 'relu', 'unit_dropout_1': 0.15, 'unit_dropout_2': 0.05, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'is_batch_normalization_3': True, 'unit_batch': 128}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HYPERTUNING FOR MODEL CNN 10 LAYERS ===\n",
        "params_grid = {\n",
        "  'layer_1_grid': [100, 128, 200, 256],\n",
        "  'layer_2_grid': [100, 128, 200, 256],\n",
        "  'layer_3_grid': [100, 128, 200, 256],\n",
        "  'layer_4_grid': [100, 128, 200, 256],\n",
        "  'layer_5_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_6_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_7_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_8_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_9_grid': [8, 16, 32, 64, 75],\n",
        "  'activation_layer_1_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_2_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_3_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_4_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_5_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_6_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_7_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_8_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_9_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_10_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'dropout_1_grid': [0, .05, .1, .15],\n",
        "  'dropout_2_grid': [0, .05, .1, .15],\n",
        "  'dropout_3_grid': [0, .05, .1, .15],\n",
        "  'dropout_4_grid': [0, .05, .1, .15],\n",
        "  'dropout_5_grid': [0, .05, .1, .15],\n",
        "  'dropout_6_grid': [0, .05, .1, .15],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(xdc\n",
        "  encdata,\n",
        "  tf_models.model_cnn10,\n",
        "  params_grid,\n",
        "  n_iterations = 200,\n",
        "  is_verbose_iterations = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzKygPBzr9VJ",
        "outputId": "d030194e-765f-427a-bc8d-7b0352a0da31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 0\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (1456, 24, 7, 1)\n",
            ">> CNN10 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.959\n",
            "best_params = {'unit_layer_1': 100, 'unit_layer_2': 256, 'unit_layer_3': 256, 'unit_layer_4': 128, 'unit_layer_5': 32, 'unit_layer_6': 16, 'unit_layer_7': 32, 'unit_layer_8': 8, 'unit_layer_9': 32, 'activation_layer_1': 'relu', 'activation_layer_2': 'tanh', 'activation_layer_3': 'softmax', 'activation_layer_4': 'softmax', 'activation_layer_5': 'softmax', 'activation_layer_6': 'tanh', 'activation_layer_7': 'softmax', 'activation_layer_8': 'tanh', 'activation_layer_9': 'softmax', 'activation_layer_10': 'relu', 'unit_dropout_1': 0.15, 'unit_dropout_2': 0.15, 'unit_dropout_3': 0.15, 'unit_dropout_4': 0.05, 'unit_dropout_5': 0.1, 'unit_dropout_6': 0.05, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'is_batch_normalization_3': True, 'is_batch_normalization_4': True, 'is_batch_normalization_5': True, 'is_batch_normalization_6': True, 'is_batch_normalization_7': True, 'unit_batch': 64}\n",
            "\n",
            "current data set: 1\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (5850, 24, 7, 1)\n",
            ">> CNN10 hypertuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_grid = {\n",
        "  'layer_1_grid': [100, 128, 200, 256],\n",
        "  'layer_2_grid': [100, 128, 200, 256],\n",
        "  'layer_3_grid': [100, 128, 200, 256],\n",
        "  'layer_4_grid': [100, 128, 200, 256],\n",
        "  'layer_5_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_6_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_7_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_8_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_9_grid': [8, 16, 32, 64, 75],\n",
        "  'activation_layer_1_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_2_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_3_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_4_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_5_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_6_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_7_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_8_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_9_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_10_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'dropout_1_grid': [0, .05, .1, .15],\n",
        "  'dropout_2_grid': [0, .05, .1, .15],\n",
        "  'dropout_3_grid': [0, .05, .1, .15],\n",
        "  'dropout_4_grid': [0, .05, .1, .15],\n",
        "  'dropout_5_grid': [0, .05, .1, .15],\n",
        "  'dropout_6_grid': [0, .05, .1, .15],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(\n",
        "  encdata,\n",
        "  tf_models.model_cnn10,\n",
        "  params_grid,\n",
        "  n_iterations = 200,\n",
        "  is_verbose_iterations = False,\n",
        "  i_data_min = 1,\n",
        "  i_data_sup = 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm_ha9O8X6CR",
        "outputId": "d22265f7-3fdd-48f5-da10-73a57b642854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 1\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (5850, 24, 7, 1)\n",
            ">> CNN10 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.737\n",
            "best_params = {'unit_layer_1': 128, 'unit_layer_2': 128, 'unit_layer_3': 200, 'unit_layer_4': 256, 'unit_layer_5': 75, 'unit_layer_6': 32, 'unit_layer_7': 16, 'unit_layer_8': 64, 'unit_layer_9': 64, 'activation_layer_1': 'tanh', 'activation_layer_2': 'tanh', 'activation_layer_3': 'relu', 'activation_layer_4': 'softmax', 'activation_layer_5': 'tanh', 'activation_layer_6': 'tanh', 'activation_layer_7': 'relu', 'activation_layer_8': 'tanh', 'activation_layer_9': 'softmax', 'activation_layer_10': 'relu', 'unit_dropout_1': 0.15, 'unit_dropout_2': 0.15, 'unit_dropout_3': 0.05, 'unit_dropout_4': 0.05, 'unit_dropout_5': 0.1, 'unit_dropout_6': 0.15, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'is_batch_normalization_3': True, 'is_batch_normalization_4': True, 'is_batch_normalization_5': True, 'is_batch_normalization_6': True, 'is_batch_normalization_7': True, 'unit_batch': 256}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_grid = {\n",
        "  'layer_1_grid': [100, 128, 200, 256],\n",
        "  'layer_2_grid': [100, 128, 200, 256],\n",
        "  'layer_3_grid': [100, 128, 200, 256],\n",
        "  'layer_4_grid': [100, 128, 200, 256],\n",
        "  'layer_5_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_6_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_7_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_8_grid': [8, 16, 32, 64, 75],\n",
        "  'layer_9_grid': [8, 16, 32, 64, 75],\n",
        "  'activation_layer_1_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_2_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_3_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_4_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_5_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_6_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_7_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_8_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_9_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'activation_layer_10_grid': ['relu', 'softmax', 'tanh'],\n",
        "  'dropout_1_grid': [0, .05, .1, .15],\n",
        "  'dropout_2_grid': [0, .05, .1, .15],\n",
        "  'dropout_3_grid': [0, .05, .1, .15],\n",
        "  'dropout_4_grid': [0, .05, .1, .15],\n",
        "  'dropout_5_grid': [0, .05, .1, .15],\n",
        "  'dropout_6_grid': [0, .05, .1, .15],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(\n",
        "  encdata,\n",
        "  tf_models.model_cnn10,\n",
        "  params_grid,\n",
        "  n_iterations = 200,\n",
        "  is_verbose_iterations = False,\n",
        "  i_data_min = 2,\n",
        "  i_data_sup = 3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vagajsK6X9rg",
        "outputId": "b199657f-a95c-404c-fdf0-dd3c1be82bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 2\n",
            "x_boot.shape: (4000, 24, 7, 1)\n",
            "x_test.shape: (5444, 24, 7, 1)\n",
            ">> CNN10 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.813\n",
            "best_params = {'unit_layer_1': 100, 'unit_layer_2': 200, 'unit_layer_3': 256, 'unit_layer_4': 100, 'unit_layer_5': 75, 'unit_layer_6': 8, 'unit_layer_7': 75, 'unit_layer_8': 32, 'unit_layer_9': 8, 'activation_layer_1': 'tanh', 'activation_layer_2': 'softmax', 'activation_layer_3': 'relu', 'activation_layer_4': 'softmax', 'activation_layer_5': 'softmax', 'activation_layer_6': 'tanh', 'activation_layer_7': 'softmax', 'activation_layer_8': 'relu', 'activation_layer_9': 'softmax', 'activation_layer_10': 'relu', 'unit_dropout_1': 0.05, 'unit_dropout_2': 0.1, 'unit_dropout_3': 0.1, 'unit_dropout_4': 0, 'unit_dropout_5': 0.1, 'unit_dropout_6': 0, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'is_batch_normalization_3': True, 'is_batch_normalization_4': True, 'is_batch_normalization_5': True, 'is_batch_normalization_6': True, 'is_batch_normalization_7': True, 'unit_batch': 256}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HYPERTUNING FOR MODEL FNN 3 LAYERS ===\n",
        "params_grid = {\n",
        "  'layer_1_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_2_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_3_grid': [2, 5, 8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'dropout_grid': [0, .05, .1, .15, .2, .3],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(\n",
        "  encdata,\n",
        "  tf_models.model_ffn3,\n",
        "  params_grid,\n",
        "  n_iterations = 60,\n",
        "  is_verbose_iterations = False\n",
        ")"
      ],
      "metadata": {
        "id": "JWqQ2cGg4IGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffc6411-5516-402a-a9d3-b8e1a9a42242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 0\n",
            ">> FNN3 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.956\n",
            "best_params = {'unit_layer_1': 128, 'unit_layer_2': 128, 'unit_layer_3': 200, 'unit_dropout_1': 0.05, 'is_batch_normalization_1': True, 'unit_batch': 256}\n",
            "\n",
            "current data set: 1\n",
            ">> FNN3 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.764\n",
            "best_params = {'unit_layer_1': 75, 'unit_layer_2': 16, 'unit_layer_3': 100, 'unit_dropout_1': 0.15, 'is_batch_normalization_1': True, 'unit_batch': 32}\n",
            "\n",
            "current data set: 2\n",
            ">> FNN3 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.722\n",
            "best_params = {'unit_layer_1': 64, 'unit_layer_2': 100, 'unit_layer_3': 16, 'unit_dropout_1': 0, 'is_batch_normalization_1': True, 'unit_batch': 32}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HYPERTUNING FOR MODEL FNN 5 LAYERS ===\n",
        "params_grid = {\n",
        "  'layer_1_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_2_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_3_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_4_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_5_grid': [2, 5, 8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'dropout_1_grid': [0, .05, .1, .15, .2, .3],\n",
        "  'dropout_2_grid': [0, .05, .1, .15, .2, .3],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(\n",
        "  encdata,\n",
        "  tf_models.model_ffn5,\n",
        "  params_grid,\n",
        "  n_iterations = 120,\n",
        "  is_verbose_iterations = False\n",
        ")"
      ],
      "metadata": {
        "id": "-1YpPUEQXTiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b280458-febd-4148-9e5f-3cc4bdaf66cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 0\n",
            ">> FNN5 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.954\n",
            "best_params = {'unit_layer_1': 32, 'unit_layer_2': 256, 'unit_layer_3': 64, 'unit_layer_4': 100, 'unit_layer_5': 256, 'unit_dropout_1': 0.15, 'unit_dropout_2': 0.1, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 256}\n",
            "\n",
            "current data set: 1\n",
            ">> FNN5 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.764\n",
            "best_params = {'unit_layer_1': 200, 'unit_layer_2': 8, 'unit_layer_3': 256, 'unit_layer_4': 100, 'unit_layer_5': 2, 'unit_dropout_1': 0.05, 'unit_dropout_2': 0.1, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 64}\n",
            "\n",
            "current data set: 2\n",
            ">> FNN5 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.734\n",
            "best_params = {'unit_layer_1': 100, 'unit_layer_2': 8, 'unit_layer_3': 128, 'unit_layer_4': 100, 'unit_layer_5': 32, 'unit_dropout_1': 0.1, 'unit_dropout_2': 0.05, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'unit_batch': 32}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === HYPERTUNING FOR MODEL FNN 10 LAYERS ===\n",
        "params_grid = {\n",
        "  'layer_1_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_2_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_3_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_4_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_5_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_6_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_7_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_8_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_9_grid': [8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'layer_10_grid': [2, 5, 8, 16, 32, 64, 75, 100, 128, 200, 256],\n",
        "  'dropout_1_grid': [0, .05, .1, .15, .2, .3],\n",
        "  'dropout_2_grid': [0, .05, .1, .15, .2, .3],\n",
        "  'dropout_3_grid': [0, .05, .1, .15, .2, .3],\n",
        "  'dropout_4_grid': [0, .05, .1, .15, .2, .3],\n",
        "  'batch_grid': [32, 64, 128, 256, 512]\n",
        "}\n",
        "tf_models.random_search_for_tensorflow_models(\n",
        "  encdata,\n",
        "  tf_models.model_ffn10,\n",
        "  params_grid,\n",
        "  n_iterations = 200,\n",
        "  is_verbose_iterations = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBZKEZUIFnHe",
        "outputId": "cf34600e-8dbd-4681-bd65-13509d734f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current data set: 0\n",
            ">> FNN10 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.953\n",
            "best_params = {'unit_layer_1': 200, 'unit_layer_2': 75, 'unit_layer_3': 64, 'unit_layer_4': 64, 'unit_layer_5': 200, 'unit_layer_6': 128, 'unit_layer_7': 256, 'unit_layer_8': 64, 'unit_layer_9': 8, 'unit_layer_10': 8, 'unit_dropout_1': 0, 'unit_dropout_2': 0.15, 'unit_dropout_3': 0.3, 'unit_dropout_4': 0.05, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'is_batch_normalization_3': True, 'is_batch_normalization_4': True, 'is_batch_normalization_5': True, 'is_batch_normalization_6': True, 'unit_batch': 32}\n",
            "\n",
            "current data set: 1\n",
            ">> FNN10 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.732\n",
            "best_params = {'unit_layer_1': 100, 'unit_layer_2': 8, 'unit_layer_3': 256, 'unit_layer_4': 75, 'unit_layer_5': 75, 'unit_layer_6': 16, 'unit_layer_7': 8, 'unit_layer_8': 8, 'unit_layer_9': 32, 'unit_layer_10': 2, 'unit_dropout_1': 0.15, 'unit_dropout_2': 0.15, 'unit_dropout_3': 0, 'unit_dropout_4': 0.15, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'is_batch_normalization_3': True, 'is_batch_normalization_4': True, 'is_batch_normalization_5': True, 'is_batch_normalization_6': True, 'unit_batch': 128}\n",
            "\n",
            "current data set: 2\n",
            ">> FNN10 hypertuning.\n",
            "\n",
            "\n",
            "best score: 0.714\n",
            "best_params = {'unit_layer_1': 64, 'unit_layer_2': 128, 'unit_layer_3': 32, 'unit_layer_4': 256, 'unit_layer_5': 32, 'unit_layer_6': 32, 'unit_layer_7': 128, 'unit_layer_8': 128, 'unit_layer_9': 64, 'unit_layer_10': 64, 'unit_dropout_1': 0.15, 'unit_dropout_2': 0.2, 'unit_dropout_3': 0.05, 'unit_dropout_4': 0.15, 'is_batch_normalization_1': True, 'is_batch_normalization_2': True, 'is_batch_normalization_3': True, 'is_batch_normalization_4': True, 'is_batch_normalization_5': True, 'is_batch_normalization_6': True, 'unit_batch': 64}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}